{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regex\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import urllib.request\n",
    "import joblib #load, dump pkl\n",
    "from underthesea import word_tokenize #word_tokenize of lines\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers as ppb # load model BERT\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'tiki_comments.csv'\n",
    "df = pd.read_csv(file,sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kích thước của bộ dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu có 1399 dòng và 2 cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ý nghĩa các các cột"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểu dữ liệu của các cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = df.dtypes\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cột comment dạng chuỗi là bình luận của người dùng.\n",
    "- Cột is_trust đánh giá bình luận là tích cực (1) hay tiêu cực (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',1000)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hoá dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xoá các dòng có giá trị cột comment trùng lặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đếm số lượng dòng trùng lặp\n",
    "num_duplicated_rows = df.duplicated(['comment']).sum()\n",
    "num_duplicated_rows\n",
    "# Xoá các dòng trùng\n",
    "df.drop_duplicates(subset =\"comment\", keep = 'first', inplace = True) \n",
    "\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hoá comment\n",
    "Dữ liệu hiện đang chứa những kí tự như dấu chấm câu, kí tự đặc biệt, icon,... Những kí tự này không cần thiết cho việc khai phá dữ liệu nên ta sẽ tiến hành loại bỏ chúng. Các bước loại bỏ:\n",
    "- Xoá đi các dấu chấm câu như (. , ? ; ...)\n",
    "- Xoá đi các kí tự đặc biệt: @,#,*,...\n",
    "- Xoá khoảng trắng đầu và cuối mỗi comment, xoá  khoảng trắng dư thừa giữa các từ.\n",
    "- Xoá đi icons và emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(row):\n",
    "    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
    "    row = re.sub(r'[^\\w]',' ', row) \n",
    "    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
    "        .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "        .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "        .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "        .replace(\"-\", \" \").replace(\"?\", \" \")\n",
    "    row = row.strip()\n",
    "    row = \" \".join(row.split())\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment trước khi chuẩn hoá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sau khi chuẩn hoá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(standardize_data)\n",
    "df[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu dữ liệu phục vụ cho việc train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv ('formated__dataset.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trực quan hoá dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Câu hỏi:</b> Tỉ lệ các loại comment trong tập dữ liệu.<br>\n",
    "Ta sẽ tính toán xem mỗi loại comment chiếm bao nhiêu phầm trăm (%) trong tập dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tính % số lượng các loại comment\n",
    "num_trust_cmt = df['is_trust'].value_counts()[1]\n",
    "num_not_trust_cmt = df['is_trust'].value_counts()[0]\n",
    "\n",
    "trust_ratio = ((num_trust_cmt / df.shape[0])*100).round(2);\n",
    "not_trust_ratio = ((num_not_trust_cmt / df.shape[0])*100).round(2);\n",
    "not_trust_ratio\n",
    "\n",
    "data = [trust_ratio,not_trust_ratio]\n",
    "labels = ['Tích cực', \"Tiêu cực\"]\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7)) \n",
    "plt.pie(data, labels = labels, explode = (0.1, 0), autopct='%1.1f%%',shadow=True) \n",
    "plt.title('Tỉ lệ % bình luận tích cực và tiêu cực')\n",
    "plt.axis('equal')\n",
    "# show plot \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lấy dữ liệu comment từ  URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n",
    "def getAllComment(url):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "source": [
    "### Word tokenizer "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Tách các comment thành từ hoặc cụm từ có nghĩa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(row):\n",
    "    return word_tokenize(row, format=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here\n",
    "def processing_data(data):\n",
    "    # 1. Standardize data\n",
    "    data_frame = pd.DataFrame(data)\n",
    "    print('data frame:', data_frame)\n",
    "    data_frame[0] = data_frame['comment'].apply(standardize_data)\n",
    "\n",
    "    # 2. Tokenizer\n",
    "    data_frame[0] = data_frame['comment'].apply(tokenizer)\n",
    "\n",
    "    # 3. Embedding\n",
    "    X_val = data_frame['comment']\n",
    "    return X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-train model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrainModel(data):\n",
    "    '''\n",
    "    Load pretrain model/ tokenizers\n",
    "    Return : features\n",
    "    '''\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    #encode lines\n",
    "    tokenized = data.apply((lambda x: tokenizer.encode(x, add_special_tokens = True,max_length=512,truncation=True)))\n",
    "\n",
    "    # get lenght max of tokenized\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    print('max len:', max_len)\n",
    "\n",
    "    # if lenght of tokenized not equal max_len , so padding value 0\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    print('padded:', padded[1])\n",
    "    print('len padded:', padded.shape)\n",
    "\n",
    "    #get attention mask ( 0: not has word, 1: has word)\n",
    "    attention_mask = np.where(padded ==0, 0,1)\n",
    "    print('attention mask:', attention_mask[1])\n",
    "\n",
    "    # Convert input to tensor\n",
    "    padded = torch.tensor(padded,dtype=torch.long)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "\n",
    "    # Load model\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(padded, attention_mask =attention_mask)\n",
    "    #     print('last hidden states:', last_hidden_states)\n",
    "\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    print('features:', features)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(url):\n",
    "    # 1. Load URL and print comments\n",
    "    data = getAllComment(url)\n",
    "#     data = load_url_selenium_tiki(url)\n",
    "    data = processing_data(data)\n",
    "    features = load_pretrainModel(data)\n",
    "    # 2. Load weights\n",
    "    model = joblib.load('save_model.pkl')\n",
    "    # 3. Result\n",
    "    result = model.predict(features)\n",
    "    print(result)\n",
    "    print(analyze(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(url = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}