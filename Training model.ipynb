{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dữ liệu đã được thu thập và chuẩn hoá ở bước Data Visualization vào dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'formated__dataset.csv'\n",
    "df = pd.read_csv(file,delimiter=',', header=None)\n",
    "print(df.shape)\n",
    "\n",
    "#Sử dụng 300 record đầu tiên để train model.\n",
    "df= df.iloc[1:300]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-train model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-train model của BERT từ thư viện.<br>\n",
    "Tiến hành tokenzier dữ liệu để chuẩn bị cho bước cập nhập trọng số cho model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#encode lines\n",
    "tokenized = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens = True, max_length=512,truncation=True)))\n",
    "print('encode',tokenized[10])\n",
    "# decode\n",
    "print('decode',tokenizer.decode(tokenized[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện cập nhập thay đổi trọng số cho model bằng dữ liệu của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all label \n",
    "labels = df[1].to_numpy().astype(np.float)\n",
    "print('labels shape:', labels.shape)\n",
    "# get lenght max of tokenized\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print('max len:', max_len)\n",
    "\n",
    "# if lenght of tokenized not equal max_len , so padding value 0\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "print('padded:', padded[1])\n",
    "print('len padded:', padded.shape)\n",
    "\n",
    "#get attention mask ( 0: not has word, 1: has word)\n",
    "attention_mask = np.where(padded ==0, 0,1)\n",
    "print('attention mask:', attention_mask[1])\n",
    "\n",
    "# Convert input to tensor\n",
    "padded = torch.tensor(padded,dtype=torch.long)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "\n",
    "# Train model\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(padded, attention_mask =attention_mask)\n",
    "#     print('last hidden states:', last_hidden_states)\n",
    "\n",
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "print('features:', features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "cl = LogisticRegression()\n",
    "cl.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá model và lưu lại model sử dụng cho bước dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "sc = cl.score(X_test, y_test)\n",
    "print('score:', sc)\n",
    "joblib.dump(cl, 'save_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
